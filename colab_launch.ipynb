{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1b2c3d4",
      "metadata": {
        "id": "a1b2c3d4"
      },
      "source": [
        "# ğŸ¬ Wan 2.1 Video Studio - Colab Launcher\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ Google Colabì—ì„œ Wan 2.1 Video Studioë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
        "T4 GPU ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì‹¤í–‰ ë°©ë²•**: ê° ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e5f6a7b8",
      "metadata": {
        "id": "e5f6a7b8",
        "outputId": "10178ecf-8ba2-47a0-84ff-9b40e73a07e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GPU: Tesla T4\n",
            "âœ… VRAM: 14.7 GB\n",
            "âœ… System RAM: 12.7 GB\n",
            "âš ï¸ ì‹œìŠ¤í…œ RAMì´ 20GB ë¯¸ë§Œì…ë‹ˆë‹¤. 14B ëª¨ë¸ì€ ìµœì†Œ 20GB ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "ğŸ’¡ í•´ê²°: Colab ë©”ë‰´ â†’ ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ 'High-RAM' ì„ íƒ\n",
            "   ë˜ëŠ” ì™¼ìª½ í•˜ë‹¨ì— RAM ë¶€ì¡± ì•Œë¦¼ ì‹œ 'ë” ë§ì€ RAM í™•ë³´' í´ë¦­\n"
          ]
        }
      ],
      "source": [
        "# GPU ë° ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ í™•ì¸\n",
        "import torch, psutil\n",
        "\n",
        "assert torch.cuda.is_available(), \"GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ GPUë¥¼ ì„ íƒí•˜ì„¸ìš”.\"\n",
        "gpu_name = torch.cuda.get_device_name(0)\n",
        "vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "\n",
        "print(f\"âœ… GPU: {gpu_name}\")\n",
        "print(f\"âœ… VRAM: {vram_gb:.1f} GB\")\n",
        "print(f\"âœ… System RAM: {ram_gb:.1f} GB\")\n",
        "\n",
        "if vram_gb < 14:\n",
        "    print(\"âš ï¸ VRAMì´ 14GB ë¯¸ë§Œì…ë‹ˆë‹¤. 480P ëª¨ë“œë§Œ ì•ˆì •ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "if ram_gb < 20:\n",
        "    print(\"âš ï¸ ì‹œìŠ¤í…œ RAMì´ 20GB ë¯¸ë§Œì…ë‹ˆë‹¤. 14B ëª¨ë¸ì€ ìµœì†Œ 20GB ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    print(\"ğŸ’¡ í•´ê²°: Colab ë©”ë‰´ â†’ ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ 'High-RAM' ì„ íƒ\")\n",
        "    print(\"   ë˜ëŠ” ì™¼ìª½ í•˜ë‹¨ì— RAM ë¶€ì¡± ì•Œë¦¼ ì‹œ 'ë” ë§ì€ RAM í™•ë³´' í´ë¦­\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì•± ì½”ë“œ ì„¤ì¹˜ + ì „ì²´ í™˜ê²½ ì…‹ì—…\n",
        "import os\n",
        "\n",
        "APP_DIR = \"/content/image-video-studio\"\n",
        "\n",
        "# Clone or update app code\n",
        "if not os.path.exists(APP_DIR):\n",
        "    !git clone https://github.com/hyunlord/image-video-studio.git {APP_DIR}\n",
        "else:\n",
        "    !git -C {APP_DIR} pull --ff-only\n",
        "    print(\"ì•± ì½”ë“œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. (ìµœì‹  pull ì™„ë£Œ)\")\n",
        "\n",
        "%cd {APP_DIR}\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# .env íŒŒì¼ì´ ìˆìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
        "from pathlib import Path\n",
        "env_file = Path(APP_DIR) / \".env\"\n",
        "if env_file.exists():\n",
        "    for line in env_file.read_text().splitlines():\n",
        "        line = line.strip()\n",
        "        if line and not line.startswith(\"#\") and \"=\" in line:\n",
        "            key, _, value = line.partition(\"=\")\n",
        "            if value.strip():\n",
        "                os.environ[key.strip()] = value.strip()\n",
        "    print(\"âœ… .env í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\")\n",
        "else:\n",
        "    print(\"ğŸ’¡ .env íŒŒì¼ ì—†ìŒ (ì„ íƒì‚¬í•­: .env.sample ì°¸ê³ í•˜ì—¬ ìƒì„±)\")"
      ],
      "metadata": {
        "id": "MIOEuy7v7PTI"
      },
      "id": "MIOEuy7v7PTI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d0e1f2",
      "metadata": {
        "id": "c9d0e1f2"
      },
      "outputs": [],
      "source": [
        "# Run common setup script (Wan 2.1, model download, post-processing tools)\n",
        "!bash {APP_DIR}/scripts/setup.sh --base-dir /content\n",
        "\n",
        "print(\"\\nâœ… ì „ì²´ í™˜ê²½ ì…‹ì—… ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d2e3f4",
      "metadata": {
        "id": "c1d2e3f4"
      },
      "outputs": [],
      "source": [
        "# ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ + ì„œë²„ ì‹œì‘ + í„°ë„ë§\n",
        "import os, sys, threading, subprocess\n",
        "\n",
        "# Kill any existing ngrok/server processes\n",
        "subprocess.run([\"pkill\", \"-f\", \"ngrok\"], capture_output=True)\n",
        "subprocess.run([\"fuser\", \"-k\", \"8000/tcp\"], capture_output=True)\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"WAN21_DIR\"] = \"/content/Wan2.1\"\n",
        "os.environ[\"CODEFORMER_DIR\"] = \"/content/CodeFormer\"\n",
        "os.environ[\"RIFE_DIR\"] = \"/content/RIFE\"\n",
        "os.environ[\"MODEL_CACHE_DIR\"] = \"/content/Wan2.1/ckpts/FLF2V-14B-720P\"\n",
        "\n",
        "# Add app to path\n",
        "APP_DIR = \"/content/image-video-studio\"\n",
        "if APP_DIR not in sys.path:\n",
        "    sys.path.insert(0, APP_DIR)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "try:\n",
        "    from pyngrok import ngrok\n",
        "except ImportError:\n",
        "    !pip install -q pyngrok\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "ngrok_token = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "if ngrok_token:\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "tunnel = ngrok.connect(8000)\n",
        "public_url = tunnel.public_url\n",
        "print(f\"ğŸŒ Public URL: {public_url}\")\n",
        "\n",
        "# Start uvicorn in background thread\n",
        "import uvicorn\n",
        "from backend.app import app\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"ğŸ¬ Wan 2.1 Video Studio ì‹¤í–‰ ì¤‘!\")\n",
        "print(f\"ğŸŒ ì ‘ì† URL: {public_url}\")\n",
        "print(f\"ğŸ“Š GPU ëª¨ë‹ˆí„°: {public_url}/monitor\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"\\nâš ï¸ ì´ ì…€ì„ ì¤‘ë‹¨í•˜ë©´ ì„œë²„ê°€ ì¢…ë£Œë©ë‹ˆë‹¤.\")\n",
        "print(f\"ğŸ’¡ ìœ„ URLì„ í´ë¦­í•˜ì—¬ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†í•˜ì„¸ìš”.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}